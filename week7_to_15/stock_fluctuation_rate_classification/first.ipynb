{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "train_data = pd.read_csv('./data/train.csv')\n",
    "test_data = pd.read_csv('./data/test.csv')\n",
    "sample_submission = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id        현재가      전일비    액면가     시가총액      상장주식수  외국인비율          거래량  \\\n",
      "0   0   2351.703  116.656  500.0  832.124  35392.000  1.658  2706392.610   \n",
      "1   1  11687.402   51.515    0.0  304.111   2600.000  0.490    50847.441   \n",
      "2   2   3100.000    0.000  500.0  969.000  31257.000  0.370        0.000   \n",
      "3   3   9408.961  254.445    0.0  292.195   3105.573  1.905   132966.463   \n",
      "4   4   2226.067  114.968  100.0  605.343  27191.000  2.551   522215.695   \n",
      "\n",
      "      PER    ROE  label  \n",
      "0  19.116   6.50      0  \n",
      "1     NaN    NaN      0  \n",
      "2   7.088  18.71      1  \n",
      "3     NaN    NaN      0  \n",
      "4     NaN    NaN      2  \n",
      "   id        현재가      전일비     액면가       시가총액     상장주식수  외국인비율         거래량  \\\n",
      "0   0  65198.863  304.482     0.0   1212.443    1860.0  0.081    4793.170   \n",
      "1   1   6406.595  171.084   500.0   3711.403   57931.0  1.209  282689.080   \n",
      "2   2   4555.651  217.911   500.0   1596.002   35038.0  5.360  214691.924   \n",
      "3   3  25048.754  490.409  5000.0  26874.700  107291.0  4.048  418903.868   \n",
      "4   4   6526.482   22.684   500.0   1165.662   17858.0  0.959   10646.274   \n",
      "\n",
      "       PER     ROE  \n",
      "0      NaN     NaN  \n",
      "1   17.645   22.02  \n",
      "2 -216.934     NaN  \n",
      "3   -1.540 -117.79  \n",
      "4  -25.100   -1.96  \n",
      "   id  label\n",
      "0   0      0\n",
      "1   1      0\n",
      "2   2      0\n",
      "3   3      0\n",
      "4   4      0\n"
     ]
    }
   ],
   "source": [
    "# Check data\n",
    "print(train_data.head())\n",
    "print(test_data.head())\n",
    "print(sample_submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id       0\n",
      "현재가      0\n",
      "전일비      0\n",
      "액면가      0\n",
      "시가총액     0\n",
      "상장주식수    0\n",
      "외국인비율    0\n",
      "거래량      0\n",
      "PER      0\n",
      "ROE      0\n",
      "label    0\n",
      "dtype: int64\n",
      "id       0\n",
      "현재가      0\n",
      "전일비      0\n",
      "액면가      0\n",
      "시가총액     0\n",
      "상장주식수    0\n",
      "외국인비율    0\n",
      "거래량      0\n",
      "PER      0\n",
      "ROE      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocessing\n",
    "\n",
    "# Check missing values\n",
    "# print(train_data.isnull().sum())\n",
    "# print(test_data.isnull().sum())\n",
    "\n",
    "# Drop missing values\n",
    "# train_data = train_data.dropna()\n",
    "# test_data = test_data.dropna()\n",
    "\n",
    "# 필요시 결측치 처리 (예: 평균값으로 채우기)\n",
    "train_data.fillna(train_data.mean(), inplace=True)\n",
    "test_data.fillna(test_data.mean(), inplace=True)\n",
    "\n",
    "# Check missing values again\n",
    "print(train_data.isnull().sum())\n",
    "print(test_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature and Lable 분리\n",
    "train_features = train_data.drop(columns=['label'], axis=1) # label은 예측할 값이라고 가정\n",
    "train_labels = train_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_features_scaled = scaler.fit_transform(train_features)\n",
    "test_features_scaled = scaler.transform(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3 모델 선택 및 학습\n",
    "Random Forest 모델을 사용해 예측 진행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated MSE: 0.8656897959183674\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(model, train_features_scaled, train_labels, cv=5, scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(f'Cross-validated MSE: {-cv_scores.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of test data: 1207\n",
      "Lenght of predictions: 750\n",
      "Lenght of sample_submission: 1207\n"
     ]
    }
   ],
   "source": [
    "# 길이 확인\n",
    "print(f\"Lenght of test data: {len(test_data)}\")\n",
    "print(f\"Lenght of predictions: {len(predictions)}\")\n",
    "print(f\"Lenght of sample_submission: {len(sample_submission)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요시 test_data를 sample_submission의 길이에 맞춰 조정\n",
    "if len(test_data) != len(predictions):\n",
    "  test_data = test_data.head(len(sample_submission))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정규화 (변경된 test_data를 사용)\n",
    "test_features_scaled = scaler.transform(test_data)\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_features_scaled, train_labels)\n",
    "\n",
    "# Predict the test data\n",
    "predictions = model.predict(test_features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions to a CSV file\n",
    "sample_submission['label'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions to a CSV file\n",
    "sample_submission['label'] = predictions\n",
    "sample_submission.to_csv('./data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.8518775510204082\n"
     ]
    }
   ],
   "source": [
    "# MAE\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_features_scaled, train_labels, test_size=0.2, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "val_predictions = model.predict(X_val)\n",
    "\n",
    "mae = mean_absolute_error(y_val, val_predictions)\n",
    "print(f'Mean Absolute Error: {mae}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
